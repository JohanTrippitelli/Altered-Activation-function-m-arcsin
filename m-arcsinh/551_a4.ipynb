{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XrL5xEJZ12s",
        "outputId": "fd654509-55f8-410d-85cb-60687ace4851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'Iris' Dataset\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR MLP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: identity, Accuracy: 1.0, Time: 0.44463109970092773\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: logistic, Accuracy: 1.0, Time: 0.5954639911651611\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: tanh, Accuracy: 1.0, Time: 1.053485631942749\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: relu, Accuracy: 1.0, Time: 0.7498431205749512\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Activation: m-arcsinh, Accuracy: 0.9777777777777777, Time: 13.33440351486206\n",
            "precision score  0.9793650793650793\n",
            "recall score  0.9777777777777777\n",
            "f1 score  0.9777448559670783\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR SVM\n",
            "linear 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.008515357971191406s\n",
            "\n",
            "poly 0.4222222222222222\n",
            "precision score  0.1782716049382716\n",
            "recall score  0.4222222222222222\n",
            "f1 score  0.25069444444444444\n",
            "Training time: 0.00938725471496582s\n",
            "\n",
            "rbf 0.6666666666666666\n",
            "precision score  0.5319865319865319\n",
            "recall score  0.6666666666666666\n",
            "f1 score  0.5733618233618234\n",
            "Training time: 0.008614063262939453s\n",
            "\n",
            "sigmoid 0.4666666666666667\n",
            "precision score  0.47545219638242897\n",
            "recall score  0.4666666666666667\n",
            "f1 score  0.33581839904420546\n",
            "Training time: 0.003610372543334961s\n",
            "\n",
            "<function m_arcsinh at 0x7f27b6751c60> 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.013750076293945312s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Johan Trippitelli - StudentID: 260917958\n",
        "# Christopher Chong, StudentID: 260976714\n",
        "# Minh Anh Trinh, StudentID: 260853143\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Imports from sklearn\n",
        "import tensorflow as tf\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import time\n",
        "\n",
        "# Loading Datasets\n",
        "print(\"Results for 'Iris' Dataset\")\n",
        "dataset = datasets.load_iris()\n",
        "\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Splitting Datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Define the new activation/Kernel function proposed in the article\n",
        "def m_arcsinh(data, Y):\n",
        "    return np.dot((\n",
        "          1/3*np.arcsinh(data))*(1/4*np.sqrt(np.abs(data))),\n",
        "          (1/3*np.arcsinh(Y.T))*(1/4*np.sqrt(np.abs(Y.T))\n",
        "          ))\n",
        "\n",
        "# Updated custom activation function\n",
        "def m_arcsinh_tf(x):\n",
        "    return tf.multiply(\n",
        "        1 / 3 * tf.asinh(x),\n",
        "        1 / 4 * tf.sqrt(tf.abs(x))\n",
        "    )\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR MLP\")\n",
        "# MLP (Use custom class for m_arcsinh)\n",
        "for activation in ('identity', 'logistic', 'tanh', 'relu'):\n",
        "    classifier = MLPClassifier(activation=activation, random_state=1, max_iter=300)\n",
        "\n",
        "    start = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(f\"Activation: {activation}, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print()\n",
        "# Define a neural Net using tensor flow for the new activation function\n",
        "# Build a simple neural network with a custom activation function\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=m_arcsinh_tf),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "stop = time.time()\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Activation: m-arcsinh, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR SVM\")\n",
        "\n",
        "# SVM\n",
        "\n",
        "\n",
        "for kernel in (\"linear\", \"poly\", \"rbf\", \"sigmoid\", m_arcsinh):\n",
        "    classifier = svm.SVC(kernel=kernel, gamma=0.001, random_state=13, class_weight='balanced')\n",
        "    start = time.time()\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(kernel, accuracy_score(y_test, y_pred))\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "uIGAF62qc69v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading Datasets\n",
        "print(\"Results for 'Breast Cancer Wisconsin' Dataset\")\n",
        "dataset = datasets.load_breast_cancer()\n",
        "\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Splitting Datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Define the new activation/Kernel function proposed in the article\n",
        "def m_arcsinh(data, Y):\n",
        "    return np.dot((\n",
        "          1/3*np.arcsinh(data))*(1/4*np.sqrt(np.abs(data))),\n",
        "          (1/3*np.arcsinh(Y.T))*(1/4*np.sqrt(np.abs(Y.T))\n",
        "          ))\n",
        "\n",
        "# Updated custom activation function\n",
        "def m_arcsinh_tf(x):\n",
        "    return tf.multiply(\n",
        "        1 / 3 * tf.asinh(x),\n",
        "        1 / 4 * tf.sqrt(tf.abs(x))\n",
        "    )\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR MLP\")\n",
        "# MLP (Use custom class for m_arcsinh)\n",
        "for activation in ('identity', 'logistic', 'tanh', 'relu'):\n",
        "    classifier = MLPClassifier(activation=activation, random_state=1, max_iter=300)\n",
        "\n",
        "    start = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(f\"Activation: {activation}, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print()\n",
        "# Define a neural Net using tensor flow for the new activation function\n",
        "# Build a simple neural network with a custom activation function\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=m_arcsinh_tf),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "stop = time.time()\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Activation: m-arcsinh, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "print()\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR SVM\")\n",
        "\n",
        "# SVM\n",
        "\n",
        "\n",
        "for kernel in (\"linear\", \"poly\", \"rbf\", \"sigmoid\", m_arcsinh):\n",
        "    classifier = svm.SVC(kernel=kernel, gamma=0.001, random_state=13, class_weight='balanced')\n",
        "    start = time.time()\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(kernel, accuracy_score(y_test, y_pred))\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-CpMPe8dBrN",
        "outputId": "6c953b8e-27d4-4d40-f139-c04775cee1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'Breast Cancer Wisconsin' Dataset\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR MLP\n",
            "Activation: identity, Accuracy: 0.9473684210526315, Time: 1.2133541107177734\n",
            "precision score  0.9514695830485304\n",
            "recall score  0.9473684210526315\n",
            "f1 score  0.9464615931721194\n",
            "\n",
            "Activation: logistic, Accuracy: 0.956140350877193, Time: 1.458378553390503\n",
            "precision score  0.9590258541089566\n",
            "recall score  0.956140350877193\n",
            "f1 score  0.9555325704030802\n",
            "\n",
            "Activation: tanh, Accuracy: 0.9649122807017544, Time: 2.707644462585449\n",
            "precision score  0.9652053622194477\n",
            "recall score  0.9649122807017544\n",
            "f1 score  0.9647382344750767\n",
            "\n",
            "Activation: relu, Accuracy: 0.9385964912280702, Time: 1.7019827365875244\n",
            "precision score  0.9441070625281152\n",
            "recall score  0.9385964912280702\n",
            "f1 score  0.937318446911604\n",
            "\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Activation: m-arcsinh, Accuracy: 0.9649122807017544, Time: 24.65878677368164\n",
            "precision score  0.9652053622194477\n",
            "recall score  0.9649122807017544\n",
            "f1 score  0.9647382344750767\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR SVM\n",
            "linear 0.956140350877193\n",
            "precision score  0.9569049312470365\n",
            "recall score  0.956140350877193\n",
            "f1 score  0.9558014271241044\n",
            "Training time: 1.553403615951538s\n",
            "\n",
            "poly 0.9473684210526315\n",
            "precision score  0.9505774598452308\n",
            "recall score  0.9473684210526315\n",
            "f1 score  0.9477752351894229\n",
            "Training time: 140.72434258460999s\n",
            "\n",
            "rbf 0.9122807017543859\n",
            "precision score  0.9159354403792905\n",
            "recall score  0.9122807017543859\n",
            "f1 score  0.9129587253157045\n",
            "Training time: 0.018380165100097656s\n",
            "\n",
            "sigmoid 0.37719298245614036\n",
            "precision score  0.1422745460141582\n",
            "recall score  0.37719298245614036\n",
            "f1 score  0.20661526427533802\n",
            "Training time: 0.012763261795043945s\n",
            "\n",
            "<function m_arcsinh at 0x7d832a9225f0> 0.9912280701754386\n",
            "precision score  0.991427432216906\n",
            "recall score  0.9912280701754386\n",
            "f1 score  0.9912473774311051\n",
            "Training time: 0.010173559188842773s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading Datasets\n",
        "print(\"Results for 'faces' Dataset\")\n",
        "dataset = datasets.fetch_olivetti_faces()\n",
        "\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Splitting Datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Define the new activation/Kernel function proposed in the article\n",
        "def m_arcsinh(data, Y):\n",
        "    return np.dot((\n",
        "          1/3*np.arcsinh(data))*(1/4*np.sqrt(np.abs(data))),\n",
        "          (1/3*np.arcsinh(Y.T))*(1/4*np.sqrt(np.abs(Y.T))\n",
        "          ))\n",
        "\n",
        "# Updated custom activation function\n",
        "def m_arcsinh_tf(x):\n",
        "    return tf.multiply(\n",
        "        1 / 3 * tf.asinh(x),\n",
        "        1 / 4 * tf.sqrt(tf.abs(x))\n",
        "    )\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR MLP\")\n",
        "# MLP (Use custom class for m_arcsinh)\n",
        "for activation in ('identity', 'logistic', 'tanh', 'relu'):\n",
        "    classifier = MLPClassifier(activation=activation, random_state=1, max_iter=300)\n",
        "\n",
        "    start = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(f\"Activation: {activation}, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print()\n",
        "# Define a neural Net using tensor flow for the new activation function\n",
        "# Build a simple neural network with a custom activation function\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=m_arcsinh_tf),\n",
        "    tf.keras.layers.Dense(40, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "stop = time.time()\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Activation: m-arcsinh, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "print()\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR SVM\")\n",
        "\n",
        "# SVM\n",
        "\n",
        "\n",
        "for kernel in (\"linear\", \"poly\", \"rbf\", \"sigmoid\", m_arcsinh):\n",
        "    classifier = svm.SVC(kernel=kernel, gamma=0.001, random_state=13, class_weight='balanced')\n",
        "    start = time.time()\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(kernel, accuracy_score(y_test, y_pred))\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "VCxw4m4tgmqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc90f4e-03c8-4c80-949d-29d3a0af6ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'faces' Dataset\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR MLP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: identity, Accuracy: 0.9625, Time: 10.41207480430603\n",
            "precision score  0.978125\n",
            "recall score  0.9625\n",
            "f1 score  0.9648484848484848\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: logistic, Accuracy: 0.9375, Time: 6.654927730560303\n",
            "precision score  0.9593749999999999\n",
            "recall score  0.9375\n",
            "f1 score  0.9353246753246752\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: tanh, Accuracy: 0.9625, Time: 13.22520112991333\n",
            "precision score  0.9645833333333333\n",
            "recall score  0.9625\n",
            "f1 score  0.961904761904762\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: relu, Accuracy: 0.825, Time: 12.581263065338135\n",
            "precision score  0.8570833333333333\n",
            "recall score  0.825\n",
            "f1 score  0.8130230880230881\n",
            "\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "Activation: m-arcsinh, Accuracy: 0.9625, Time: 20.350996255874634\n",
            "precision score  0.9733333333333333\n",
            "recall score  0.9625\n",
            "f1 score  0.9617929292929291\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR SVM\n",
            "linear 0.975\n",
            "precision score  0.98125\n",
            "recall score  0.975\n",
            "f1 score  0.974134199134199\n",
            "Training time: 0.40329742431640625s\n",
            "\n",
            "poly 0.825\n",
            "precision score  0.8691666666666666\n",
            "recall score  0.825\n",
            "f1 score  0.8153841991341991\n",
            "Training time: 0.31621265411376953s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rbf 0.325\n",
            "precision score  0.35297619047619044\n",
            "recall score  0.325\n",
            "f1 score  0.3223015873015873\n",
            "Training time: 0.3638789653778076s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid 0.0\n",
            "precision score  0.0\n",
            "recall score  0.0\n",
            "f1 score  0.0\n",
            "Training time: 0.30593252182006836s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function m_arcsinh at 0x7d832a01d7e0> 0.875\n",
            "precision score  0.8881249999999999\n",
            "recall score  0.875\n",
            "f1 score  0.8621401515151517\n",
            "Training time: 0.11545705795288086s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading Datasets\n",
        "print(\"Results for 'wine' Dataset\")\n",
        "dataset = datasets.load_wine()\n",
        "\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Splitting Datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Define the new activation/Kernel function proposed in the article\n",
        "def m_arcsinh(data, Y):\n",
        "    return np.dot((\n",
        "          1/3*np.arcsinh(data))*(1/4*np.sqrt(np.abs(data))),\n",
        "          (1/3*np.arcsinh(Y.T))*(1/4*np.sqrt(np.abs(Y.T))\n",
        "          ))\n",
        "\n",
        "# Updated custom activation function\n",
        "def m_arcsinh_tf(x):\n",
        "    return tf.multiply(\n",
        "        1 / 3 * tf.asinh(x),\n",
        "        1 / 4 * tf.sqrt(tf.abs(x))\n",
        "    )\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR MLP\")\n",
        "# MLP (Use custom class for m_arcsinh)\n",
        "for activation in ('identity', 'logistic', 'tanh', 'relu'):\n",
        "    classifier = MLPClassifier(activation=activation, random_state=1, max_iter=300)\n",
        "\n",
        "    start = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(f\"Activation: {activation}, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print()\n",
        "# Define a neural Net using tensor flow for the new activation function\n",
        "# Build a simple neural network with a custom activation function\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=m_arcsinh_tf),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "stop = time.time()\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Activation: m-arcsinh, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "print()\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR SVM\")\n",
        "\n",
        "# SVM\n",
        "\n",
        "\n",
        "for kernel in (\"linear\", \"poly\", \"rbf\", \"sigmoid\", m_arcsinh):\n",
        "    classifier = svm.SVC(kernel=kernel, gamma=0.001, random_state=13, class_weight='balanced')\n",
        "    start = time.time()\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(kernel, accuracy_score(y_test, y_pred))\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "XBWfzkcNg9lw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec71d6b5-33e6-41d4-c545-cc575dc65391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'wine' Dataset\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR MLP\n",
            "Activation: identity, Accuracy: 0.2777777777777778, Time: 0.021385669708251953\n",
            "precision score  0.12544802867383512\n",
            "recall score  0.2777777777777778\n",
            "f1 score  0.1728395061728395\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: logistic, Accuracy: 1.0, Time: 0.25983595848083496\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: tanh, Accuracy: 0.9722222222222222, Time: 0.49001193046569824\n",
            "precision score  0.974074074074074\n",
            "recall score  0.9722222222222222\n",
            "f1 score  0.9721867461331064\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: relu, Accuracy: 0.9166666666666666, Time: 0.22077655792236328\n",
            "precision score  0.9313725490196079\n",
            "recall score  0.9166666666666666\n",
            "f1 score  0.9162162674707477\n",
            "\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Activation: m-arcsinh, Accuracy: 1.0, Time: 5.776904582977295\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR SVM\n",
            "linear 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.26584529876708984s\n",
            "\n",
            "poly 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.3106238842010498s\n",
            "\n",
            "rbf 0.75\n",
            "precision score  0.8115384615384615\n",
            "recall score  0.75\n",
            "f1 score  0.7643298059964726\n",
            "Training time: 0.004867076873779297s\n",
            "\n",
            "sigmoid 0.2222222222222222\n",
            "precision score  0.04938271604938271\n",
            "recall score  0.2222222222222222\n",
            "f1 score  0.0808080808080808\n",
            "Training time: 0.004385232925415039s\n",
            "\n",
            "<function m_arcsinh at 0x7d83bc624940> 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.004260540008544922s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading Datasets\n",
        "print(\"Results for 'digits' Dataset\")\n",
        "dataset = datasets.load_digits()\n",
        "\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Splitting Datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Define the new activation/Kernel function proposed in the article\n",
        "def m_arcsinh(data, Y):\n",
        "    return np.dot((\n",
        "          1/3*np.arcsinh(data))*(1/4*np.sqrt(np.abs(data))),\n",
        "          (1/3*np.arcsinh(Y.T))*(1/4*np.sqrt(np.abs(Y.T))\n",
        "          ))\n",
        "\n",
        "# Updated custom activation function\n",
        "def m_arcsinh_tf(x):\n",
        "    return tf.multiply(\n",
        "        1 / 3 * tf.asinh(x),\n",
        "        1 / 4 * tf.sqrt(tf.abs(x))\n",
        "    )\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR MLP\")\n",
        "# MLP (Use custom class for m_arcsinh)\n",
        "for activation in ('identity', 'logistic', 'tanh', 'relu'):\n",
        "    classifier = MLPClassifier(activation=activation, random_state=1, max_iter=300)\n",
        "\n",
        "    start = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(f\"Activation: {activation}, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print()\n",
        "# Define a neural Net using tensor flow for the new activation function\n",
        "# Build a simple neural network with a custom activation function\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=m_arcsinh_tf),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "stop = time.time()\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Activation: m-arcsinh, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "print()\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR SVM\")\n",
        "\n",
        "# SVM\n",
        "\n",
        "\n",
        "for kernel in (\"linear\", \"poly\", \"rbf\", \"sigmoid\", m_arcsinh):\n",
        "    classifier = svm.SVC(kernel=kernel, gamma=0.001, random_state=13, class_weight='balanced')\n",
        "    start = time.time()\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(kernel, accuracy_score(y_test, y_pred))\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x01dP_DzkRUs",
        "outputId": "c005610d-1108-4e93-f5f0-b089548d6785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'digits' Dataset\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR MLP\n",
            "Activation: identity, Accuracy: 0.9722222222222222, Time: 1.9680030345916748\n",
            "precision score  0.9729350194183953\n",
            "recall score  0.9722222222222222\n",
            "f1 score  0.9723993910737186\n",
            "\n",
            "Activation: logistic, Accuracy: 0.9777777777777777, Time: 2.7186789512634277\n",
            "precision score  0.9780835005402794\n",
            "recall score  0.9777777777777777\n",
            "f1 score  0.9777731000981109\n",
            "\n",
            "Activation: tanh, Accuracy: 0.9740740740740741, Time: 2.715550184249878\n",
            "precision score  0.974228844313793\n",
            "recall score  0.9740740740740741\n",
            "f1 score  0.9740642133201871\n",
            "\n",
            "Activation: relu, Accuracy: 0.975925925925926, Time: 1.3161685466766357\n",
            "precision score  0.9761083005775337\n",
            "recall score  0.975925925925926\n",
            "f1 score  0.9758739675231098\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d83bc626830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 2ms/step\n",
            "Activation: m-arcsinh, Accuracy: 0.9685185185185186, Time: 42.280505895614624\n",
            "precision score  0.9691231555202352\n",
            "recall score  0.9685185185185186\n",
            "f1 score  0.9685722011146233\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR SVM\n",
            "linear 0.9796296296296296\n",
            "precision score  0.9797546655664472\n",
            "recall score  0.9796296296296296\n",
            "f1 score  0.9796218196385608\n",
            "Training time: 0.027170419692993164s\n",
            "\n",
            "poly 0.9888888888888889\n",
            "precision score  0.9890656565656566\n",
            "recall score  0.9888888888888889\n",
            "f1 score  0.9889440001695969\n",
            "Training time: 0.030024290084838867s\n",
            "\n",
            "rbf 0.9907407407407407\n",
            "precision score  0.990743598781524\n",
            "recall score  0.9907407407407407\n",
            "f1 score  0.9907086431861551\n",
            "Training time: 0.07593131065368652s\n",
            "\n",
            "sigmoid 0.7222222222222222\n",
            "precision score  0.7435156636160563\n",
            "recall score  0.7222222222222222\n",
            "f1 score  0.711391466598291\n",
            "Training time: 0.22981834411621094s\n",
            "\n",
            "<function m_arcsinh at 0x7d831ae8e050> 0.9833333333333333\n",
            "precision score  0.9835135177317114\n",
            "recall score  0.9833333333333333\n",
            "f1 score  0.9832784356019747\n",
            "Training time: 0.04315304756164551s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading Datasets\n",
        "print(\"Results for 'lfw people' Dataset\")\n",
        "#dataset = datasets.fetch_lfw_people()\n",
        "\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Splitting Datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define the new activation/Kernel function proposed in the article\n",
        "def m_arcsinh(data, Y):\n",
        "    return np.dot((\n",
        "          1/3*np.arcsinh(data))*(1/4*np.sqrt(np.abs(data))),\n",
        "          (1/3*np.arcsinh(Y.T))*(1/4*np.sqrt(np.abs(Y.T))\n",
        "          ))\n",
        "\n",
        "# Updated custom activation function\n",
        "def m_arcsinh_tf(x):\n",
        "    return tf.multiply(\n",
        "        1 / 3 * tf.asinh(x),\n",
        "        1 / 4 * tf.sqrt(tf.abs(x))\n",
        "    )\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR MLP\")\n",
        "# MLP (Use custom class for m_arcsinh)\n",
        "for activation in ('identity', 'logistic', 'tanh', 'relu'):\n",
        "    classifier = MLPClassifier(activation=activation, random_state=1, max_iter=300)\n",
        "\n",
        "    start = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(f\"Activation: {activation}, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print()\n",
        "# Define a neural Net using tensor flow for the new activation function\n",
        "# Build a simple neural network with a custom activation function\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=m_arcsinh_tf),\n",
        "    tf.keras.layers.Dense(5750, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "stop = time.time()\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Activation: m-arcsinh, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "print()\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR SVM\")\n",
        "\n",
        "# SVM\n",
        "\n",
        "\n",
        "for kernel in (\"linear\", \"poly\", \"rbf\", \"sigmoid\", m_arcsinh):\n",
        "    classifier = svm.SVC(kernel=kernel, gamma=0.001, random_state=13, class_weight='balanced')\n",
        "    start = time.time()\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(kernel, accuracy_score(y_test, y_pred))\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-OaioMGkf6r",
        "outputId": "7039c61d-bdc2-4258-be6f-c7071def3c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'lfw people' Dataset\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR MLP\n",
            "Activation: identity, Accuracy: 0.9733333333333334, Time: 2.1516294479370117\n",
            "precision score  0.9737374918778426\n",
            "recall score  0.9733333333333334\n",
            "f1 score  0.9734090176260031\n",
            "\n",
            "Activation: logistic, Accuracy: 0.9777777777777777, Time: 2.9273247718811035\n",
            "precision score  0.9780236228544499\n",
            "recall score  0.9777777777777777\n",
            "f1 score  0.9777253199065142\n",
            "\n",
            "Activation: tanh, Accuracy: 0.9777777777777777, Time: 5.753305435180664\n",
            "precision score  0.9781375829684101\n",
            "recall score  0.9777777777777777\n",
            "f1 score  0.9777830399642343\n",
            "\n",
            "Activation: relu, Accuracy: 0.98, Time: 2.1790215969085693\n",
            "precision score  0.9803839267184805\n",
            "recall score  0.98\n",
            "f1 score  0.9800228651891272\n",
            "\n",
            "15/15 [==============================] - 0s 4ms/step\n",
            "Activation: m-arcsinh, Accuracy: 0.9711111111111111, Time: 202.5630042552948\n",
            "precision score  0.9715617283950617\n",
            "recall score  0.9711111111111111\n",
            "f1 score  0.971180440103308\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR SVM\n",
            "linear 0.9822222222222222\n",
            "precision score  0.9823823912003377\n",
            "recall score  0.9822222222222222\n",
            "f1 score  0.982164730161672\n",
            "Training time: 0.025354623794555664s\n",
            "\n",
            "poly 0.9888888888888889\n",
            "precision score  0.9888786446020489\n",
            "recall score  0.9888888888888889\n",
            "f1 score  0.9888631382377513\n",
            "Training time: 0.02841019630432129s\n",
            "\n",
            "rbf 0.9888888888888889\n",
            "precision score  0.9890443071119737\n",
            "recall score  0.9888888888888889\n",
            "f1 score  0.9888558855050082\n",
            "Training time: 0.07890510559082031s\n",
            "\n",
            "sigmoid 0.72\n",
            "precision score  0.7400641300709772\n",
            "recall score  0.72\n",
            "f1 score  0.7095031619817088\n",
            "Training time: 0.25989413261413574s\n",
            "\n",
            "<function m_arcsinh at 0x7d83bc626b90> 0.9844444444444445\n",
            "precision score  0.9848750642193265\n",
            "recall score  0.9844444444444445\n",
            "f1 score  0.9843680220106559\n",
            "Training time: 0.044373273849487305s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma chage"
      ],
      "metadata": {
        "id": "Ha8GOuarNP-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports from sklearn\n",
        "import tensorflow as tf\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import time\n",
        "\n",
        "# Loading Datasets\n",
        "print(\"Results for 'Iris' Dataset\")\n",
        "dataset = datasets.load_iris()\n",
        "\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Splitting Datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Define the new activation/Kernel function proposed in the article\n",
        "def m_arcsinh(data, Y):\n",
        "    return np.dot((\n",
        "          1/3*np.arcsinh(data))*(1/4*np.sqrt(np.abs(data))),\n",
        "          (1/3*np.arcsinh(Y.T))*(1/4*np.sqrt(np.abs(Y.T))\n",
        "          ))\n",
        "\n",
        "# Updated custom activation function\n",
        "def m_arcsinh_tf(x):\n",
        "    return tf.multiply(\n",
        "        1 / 3 * tf.asinh(x),\n",
        "        1 / 4 * tf.sqrt(tf.abs(x))\n",
        "    )\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR MLP\")\n",
        "# MLP (Use custom class for m_arcsinh)\n",
        "for activation in ('identity', 'logistic', 'tanh', 'relu'):\n",
        "    classifier = MLPClassifier(activation=activation, random_state=1, max_iter=300)\n",
        "\n",
        "    start = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(f\"Activation: {activation}, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print()\n",
        "# Define a neural Net using tensor flow for the new activation function\n",
        "# Build a simple neural network with a custom activation function\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=m_arcsinh_tf),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "stop = time.time()\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Activation: m-arcsinh, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR SVM\")\n",
        "\n",
        "# SVM\n",
        "\n",
        "gamma_values = [0.00001, 0.001, 0.1, 1, 10]\n",
        "for gamma in gamma_values:\n",
        "    classifier = svm.SVC(kernel=m_arcsinh, gamma=gamma, random_state=13, class_weight='balanced')\n",
        "    start = time.time()\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(\"gamma = \", gamma)\n",
        "    print(\"m_arcsinh\", accuracy_score(y_test, y_pred))\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3huYn-GHNRw1",
        "outputId": "a0ff69f8-79f1-44d5-8d88-869f3509843d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'Iris' Dataset\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR MLP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: identity, Accuracy: 1.0, Time: 0.5636005401611328\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: logistic, Accuracy: 1.0, Time: 1.568509578704834\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: tanh, Accuracy: 1.0, Time: 1.0736947059631348\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation: relu, Accuracy: 1.0, Time: 0.730217456817627\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Activation: m-arcsinh, Accuracy: 0.9777777777777777, Time: 11.741596937179565\n",
            "precision score  0.9793650793650793\n",
            "recall score  0.9777777777777777\n",
            "f1 score  0.9777448559670783\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR SVM\n",
            "gamma =  1e-05\n",
            "m_arcsinh 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.0025572776794433594s\n",
            "\n",
            "gamma =  0.001\n",
            "m_arcsinh 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.002223491668701172s\n",
            "\n",
            "gamma =  0.1\n",
            "m_arcsinh 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.002244710922241211s\n",
            "\n",
            "gamma =  1\n",
            "m_arcsinh 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.002190828323364258s\n",
            "\n",
            "gamma =  10\n",
            "m_arcsinh 1.0\n",
            "precision score  1.0\n",
            "recall score  1.0\n",
            "f1 score  1.0\n",
            "Training time: 0.002225637435913086s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading Datasets\n",
        "print(\"Results for 'Breast Cancer Wisconsin' Dataset\")\n",
        "dataset = datasets.load_breast_cancer()\n",
        "\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "\n",
        "# Splitting Datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Define the new activation/Kernel function proposed in the article\n",
        "def m_arcsinh(data, Y):\n",
        "    return np.dot((\n",
        "          1/3*np.arcsinh(data))*(1/4*np.sqrt(np.abs(data))),\n",
        "          (1/3*np.arcsinh(Y.T))*(1/4*np.sqrt(np.abs(Y.T))\n",
        "          ))\n",
        "\n",
        "# Updated custom activation function\n",
        "def m_arcsinh_tf(x):\n",
        "    return tf.multiply(\n",
        "        1 / 3 * tf.asinh(x),\n",
        "        1 / 4 * tf.sqrt(tf.abs(x))\n",
        "    )\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR MLP\")\n",
        "# MLP (Use custom class for m_arcsinh)\n",
        "for activation in ('identity', 'logistic', 'tanh', 'relu'):\n",
        "    classifier = MLPClassifier(activation=activation, random_state=1, max_iter=300)\n",
        "\n",
        "    start = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(f\"Activation: {activation}, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print()\n",
        "# Define a neural Net using tensor flow for the new activation function\n",
        "# Build a simple neural network with a custom activation function\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=m_arcsinh_tf),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "stop = time.time()\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Activation: m-arcsinh, Accuracy: {accuracy_score(y_test, y_pred)}, Time: {stop - start}\")\n",
        "print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "print()\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"STARTING TESTING FOR SVM\")\n",
        "\n",
        "# SVM\n",
        "\n",
        "\n",
        "gamma_values = [0.00001, 0.001, 0.1, 1, 10]\n",
        "for gamma in gamma_values:\n",
        "    classifier = svm.SVC(kernel=m_arcsinh, gamma=gamma, random_state=13, class_weight='balanced')\n",
        "    start = time.time()\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    stop = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(\"gamma = \", gamma)\n",
        "    print(\"m_arcsinh\", accuracy_score(y_test, y_pred))\n",
        "    print(\"precision score \" , precision_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"recall score \" , recall_score(y_test, y_pred, average = \"weighted\"))\n",
        "    print(\"f1 score \" , f1_score(y_test, y_pred, average = \"weighted\"))\n",
        "\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZHSl65ANUQp",
        "outputId": "8372e92b-f505-447e-9474-6b1c5d4dcf0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'Breast Cancer Wisconsin' Dataset\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR MLP\n",
            "Activation: identity, Accuracy: 0.9473684210526315, Time: 0.7936177253723145\n",
            "precision score  0.9514695830485304\n",
            "recall score  0.9473684210526315\n",
            "f1 score  0.9464615931721194\n",
            "\n",
            "Activation: logistic, Accuracy: 0.956140350877193, Time: 1.3478353023529053\n",
            "precision score  0.9590258541089566\n",
            "recall score  0.956140350877193\n",
            "f1 score  0.9555325704030802\n",
            "\n",
            "Activation: tanh, Accuracy: 0.9649122807017544, Time: 2.444345235824585\n",
            "precision score  0.9652053622194477\n",
            "recall score  0.9649122807017544\n",
            "f1 score  0.9647382344750767\n",
            "\n",
            "Activation: relu, Accuracy: 0.9385964912280702, Time: 1.5614447593688965\n",
            "precision score  0.9441070625281152\n",
            "recall score  0.9385964912280702\n",
            "f1 score  0.937318446911604\n",
            "\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Activation: m-arcsinh, Accuracy: 0.956140350877193, Time: 12.528259038925171\n",
            "precision score  0.9569049312470365\n",
            "recall score  0.956140350877193\n",
            "f1 score  0.9558014271241044\n",
            "\n",
            "----------------------------------------------------------------------------------------------------------------\n",
            "STARTING TESTING FOR SVM\n",
            "gamma =  1e-05\n",
            "m_arcsinh 0.9912280701754386\n",
            "precision score  0.991427432216906\n",
            "recall score  0.9912280701754386\n",
            "f1 score  0.9912473774311051\n",
            "Training time: 0.011986017227172852s\n",
            "\n",
            "gamma =  0.001\n",
            "m_arcsinh 0.9912280701754386\n",
            "precision score  0.991427432216906\n",
            "recall score  0.9912280701754386\n",
            "f1 score  0.9912473774311051\n",
            "Training time: 0.008340835571289062s\n",
            "\n",
            "gamma =  0.1\n",
            "m_arcsinh 0.9912280701754386\n",
            "precision score  0.991427432216906\n",
            "recall score  0.9912280701754386\n",
            "f1 score  0.9912473774311051\n",
            "Training time: 0.008307933807373047s\n",
            "\n",
            "gamma =  1\n",
            "m_arcsinh 0.9912280701754386\n",
            "precision score  0.991427432216906\n",
            "recall score  0.9912280701754386\n",
            "f1 score  0.9912473774311051\n",
            "Training time: 0.008428096771240234s\n",
            "\n",
            "gamma =  10\n",
            "m_arcsinh 0.9912280701754386\n",
            "precision score  0.991427432216906\n",
            "recall score  0.9912280701754386\n",
            "f1 score  0.9912473774311051\n",
            "Training time: 0.009271621704101562s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RSalVq2XN4li"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}